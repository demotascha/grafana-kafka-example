x-logging: &default-logging
  driver: loki
  options:
    loki-url: 'http://localhost:3100/api/prom/push'

version: '3.4'
services:
  # Infrastructure

  loki:
    image: grafana/loki:2.6.1
    command: -config.file=/etc/loki/local-config.yaml
    ports:
      - "3100:3100"

  prometheus:
    image: prom/prometheus:v2.39.1
    ports:
      - "9090:9090"
    volumes:
      - ./etc/prometheus:/workspace
    command:
      - --config.file=/workspace/prometheus.yml
      - --enable-feature=exemplar-storage
    depends_on:
      - loki
    logging: *default-logging

  tempo:
    image: grafana/tempo:1.5.0
    command: [ "--target=all", "--storage.trace.backend=local", "--storage.trace.local.path=/var/tempo", "--auth.enabled=false" ]
    ports:
      - "14250:14250"
      - "4317:4317"
    depends_on:
      - loki
    logging: *default-logging

  grafana:
    image: grafana/grafana:9.1.7
    ports:
      - "3001:3000"
    volumes:
      - ./etc/grafana/:/etc/grafana/provisioning/datasources
      - ./etc/dashboards.yaml:/etc/grafana/provisioning/dashboards/dashboards.yaml
      - ./etc/dashboards:/etc/grafana/dashboards
    depends_on:
      - loki
      - prometheus
    environment:
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_ANONYMOUS_ORG_ROLE: "Admin"
      GF_AUTH_DISABLE_LOGIN_FORM: "true"
    logging: *default-logging

# zookeeper stores metadata or the kafka cluster nodes
  zookeeper:
    image: confluentinc/cp-zookeeper:5.2.4
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    restart: always
    ports:
      - 22181:2181

# kafka_broker provides: topics, partitions for producers and consumers
  kafka_broker:
    image: confluentinc/cp-kafka:5.2.4
    depends_on:
      - zookeeper
    restart: always
    ports:
      - 29092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka_broker:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

# promtail consumes messages from a kafka topic and remote writes them to Grafana Logs
  promtail:
    image: grafana/promtail:latest
    depends_on:
      - kafka_broker
      - loki
    restart: always
    volumes:
      - type: bind
        source: ./etc/promtail/promtail-config.yml
        target: /etc/promtail/promtail-config.yml
      - /var/log:/var/logtest:ro
    entrypoint:
      - /usr/bin/promtail
      - -config.expand-env=true
      - -config.file=/etc/promtail/promtail-config.yml
    environment:
      V1: 123
      V2: 567

# kafka_producer produces messages to a kafka topic
  producer:
    image: kafka_producer
    depends_on:
      - kafka_broker
    restart: always
    volumes:
      - type: bind
        source: ./kafka
        target: /home/test/kafka
      - type: bind
        source: ./kafka/producer.py
        target: /home/test/kafka/producer.py
    entrypoint:
      - python3
      - /home/test/kafka/producer.py
      - producerThreaded
    environment:
      KAFKA_BROKER: "kafka_broker:9092"
      KAFKA_TOPIC: "grafana"
      KAFKA_PRODUCER_INTERVAL: 15

# configurators creates the kafka topic
  configurator:
    image: kafka_producer
    depends_on:
      - kafka_broker
    volumes:
      - type: bind
        source: ./kafka
        target: /home/test/kafka
    entrypoint:
      - python3
      - /home/test/kafka/producer.py
      - createTopics
      - "300"
    environment:
      KAFKA_BROKER: "kafka_broker:9092"
      KAFKA_TOPIC: "grafana"
      KAFKA_PRODUCER_INTERVAL: 15
      
networks:
  kafka_network:
    external:
      name: kafka_docker_example_net
